{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "048dbd39",
   "metadata": {},
   "source": [
    "### Predicting  California House Prices with  Linear Regression\n",
    "\n",
    "### Objective\n",
    "* To predict California Housing Prices using the most simple Linear Regression Model and see how it performs.\n",
    "* To understand the modeling workflow using mlpack.\n",
    "\n",
    "### About the Data\n",
    " This dataset is a modified version of the California Housing dataset available from Luís Torgo's page (University of Porto). Luís Torgo obtained it from the StatLib repository (which is closed now). The dataset may also be downloaded from StatLib mirrors.\n",
    " \n",
    " This dataset is also used in a book HandsOn-ML ( a very good book and highly recommended).\n",
    " \n",
    " The dataset in this directory is almost identical to the original, with two differences:\n",
    "207 values were randomly removed from the totalbedrooms column, so we can discuss what to do with missing data. An additional categorical attribute called oceanproximity was added, indicating (very roughly) whether each block group is near the ocean, near the Bay area, inland or on an island. This allows discussing what to do with categorical data.\n",
    "Note that the block groups are called \"districts\" in the Jupyter notebooks, simply because in some contexts the name \"block group\" was confusing.\"\n",
    "\n",
    "Lets look at the features of the dataset:\n",
    "* Longitude : Longitude coordinate of the houses.\n",
    "* Latitude : Latitude coordinate of the houses.\n",
    "* Housing Median Age : Average lifespan of houses.\n",
    "* Total Rooms : Number of rooms in a location.\n",
    "* Total Bedrooms : Number of bedroooms in a location.\n",
    "* Population : Population in that location.\n",
    "* Median Income : Median Income of households in a location.\n",
    "* Median House Value : Median House Value in a location.\n",
    "* Ocean Proximity : Closeness to shore. \n",
    "\n",
    "### Approach\n",
    " Here, we will try to recreate the workflow from the book mentioned above. \n",
    " * Look at the Big Picture.\n",
    " * Get the Data.\n",
    " * Discover and Visualize the data to gain insights.\n",
    " * Pre-Process the data for the Ml Algorithm.\n",
    " * Create new features. \n",
    " * Splitting the data.\n",
    " * Training the ML model using MLPACK.\n",
    " * Residuals, Errors and Conclusion.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1929f17d",
   "metadata": {},
   "source": [
    "### Big Picture\n",
    "\n",
    "Suppose you work in a Real State Agency as an analyst or Data Scientist and your Boss wants you to predict the housing prices in a certain location. You are provided with a dataset. So, what will be the first thing to do?\n",
    "\n",
    "If you are probably jumping right into anaylsing the data and ML Algos, then this is a wrong a step. Its a big \"NO\". \n",
    " <h5> The first thing is to ask Questions. </h5>\n",
    " \n",
    " Questions like :  What will be the predictions used for? Will it be fed into some other system or not? And Many More, just to have concrete goals.\n",
    " \n",
    " So, your boss says that they will be using the data to get the predcitions so that the other team can work on some investment strategies.\n",
    " \n",
    "So, let's get started."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8513db",
   "metadata": {},
   "source": [
    "<h3> Importing Header Files </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4d4ec4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <mlpack/xeus-cling.hpp>\n",
    "#include <mlpack/core.hpp>\n",
    "#include <mlpack/methods/linear_regression/linear_regression.hpp>\n",
    "#include <mlpack/core/data/split_data.hpp>\n",
    "#include <bits/stdc++.h>\n",
    "#define WITHOUT_NUMPY 1\n",
    "#include \"matplotlibcpp.h\"\n",
    "#include \"xwidgets/ximage.hpp\"\n",
    "#include \"../utils/histogram.hpp\"\n",
    "#include \"../utils/impute.hpp\"\n",
    "#include \"../utils/pandasscatter.hpp\"\n",
    "#include \"../utils/heatmap.hpp\"\n",
    "#include \"../utils/plot.hpp\"\n",
    "\n",
    "namespace plt = matplotlibcpp;\n",
    "using namespace mlpack;\n",
    "using namespace mlpack::data;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ada155",
   "metadata": {},
   "source": [
    "<h3> Let's download the dataset. </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "401c6664",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q https://matrix.org/_matrix/media/r0/download/matrix.org/WvrgbgzkyIMbvkxLkKKNyMrO/housing.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4455b8c2",
   "metadata": {},
   "source": [
    "### Loading the Data\n",
    "Now, we need to load the dataset as armadillo matrix for further operations. Our dataset has a total of 9 features: 8 numerical and 1 categorical(ocean proximity). We need to map the categorical feature as armadillo operates on numeric values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8c518f",
   "metadata": {},
   "source": [
    "But, there's one thing which we need to do before loading the dataset as armadillo matrix, that is, to deal with any missing values. Since 207 values were removed from the original dataset from \"total_bedrooms_column\", we need to fill them using either \"mean\" or \"median\" of that feature( for numerical) and \"mode\"( for categorical\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8f953059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// The imputing functions follows this:\n",
    "// Impute(inputFile, outputFile, kind);\n",
    "// Here, inputFile is our raw file, outputFile is our new file with the imputations, \n",
    "// and kind refers to imputation method.\n",
    "\n",
    "Impute(\"housing.csv\", \"housing_imputed.csv\", \"median\");\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44b68cf",
   "metadata": {},
   "source": [
    "Let's drop the headers using sed. Sed is a unix utility which is used to parse and transform text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0a4da26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sed 1d housing_imputed.csv > housing_without_header.csv\n",
    "\n",
    "// Here, we used sed to delete the first row which is indicated by \"1d\" and created a new file with name\n",
    "// housing_without_header.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d2e2c3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "arma::mat dataset;\n",
    "data::DatasetInfo info;\n",
    "info.Type(9) = mlpack::data::Datatype::categorical;\n",
    "data::Load(\"housing_without_header.csv\", dataset, info);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "choice-victor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -1.2223e+02  -1.2222e+02  -1.2224e+02  -1.2225e+02  -1.2225e+02  -1.2225e+02\n",
      "   3.7880e+01   3.7860e+01   3.7850e+01   3.7850e+01   3.7850e+01   3.7850e+01\n",
      "   4.1000e+01   2.1000e+01   5.2000e+01   5.2000e+01   5.2000e+01   5.2000e+01\n",
      "   8.8000e+02   7.0990e+03   1.4670e+03   1.2740e+03   1.6270e+03   9.1900e+02\n",
      "   1.2900e+02   1.1060e+03   1.9000e+02   2.3500e+02   2.8000e+02   2.1300e+02\n",
      "   3.2200e+02   2.4010e+03   4.9600e+02   5.5800e+02   5.6500e+02   4.1300e+02\n",
      "   1.2600e+02   1.1380e+03   1.7700e+02   2.1900e+02   2.5900e+02   1.9300e+02\n",
      "   8.3252e+00   8.3014e+00   7.2574e+00   5.6431e+00   3.8462e+00   4.0368e+00\n",
      "   4.5260e+05   3.5850e+05   3.5210e+05   3.4130e+05   3.4220e+05   2.6970e+05\n",
      "            0            0            0            0            0            0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// Print the first 6 rows of the input data.\n",
    "std::cout << dataset.submat(0, 0, dataset.n_rows - 1 , 5)<< std::endl;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d337702",
   "metadata": {},
   "source": [
    "Did you notice something? Yes, the last row looks like it is entirely filled with '0'. Let's check our dataset to see what it corresponds to.\n",
    "It corresponds to Ocean Proximity which is a categorical value, but here it is zero.\n",
    "Why? It's because the load function loads numerical values only. This is exactly why we mapped Ocean proximity earlier.\n",
    "So, let's deal with this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d6969aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include<mlpack/core/data/one_hot_encoding.hpp>\n",
    "arma::mat encoded_dataset; \n",
    "data::OneHotEncoding(dataset, encoded_dataset, info);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb2326a",
   "metadata": {},
   "source": [
    "Here, we chose our pre-built encoding method \"One Hot Encoding\" to deal with the categorical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8bad850e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_dataset.n_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f76071",
   "metadata": {},
   "source": [
    "<h3>Visualization</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918a023a",
   "metadata": {},
   "source": [
    "Let's plot a histogram. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5881f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c0dd57a133c4ecca91802380f610915",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter widget with unique id: 5c0dd57a133c4ecca91802380f610915"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Hist(inputFile, bins, width, height, outputFile);\n",
    "Hist(\"housing.csv\", 50, 20, 15, \"histogram.png\");\n",
    "auto im = xw::image_from_file(\"histogram.png\").finalize();\n",
    "im"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c74d711",
   "metadata": {},
   "source": [
    "Let's plot a scatter plot with longitude and latitude as x and y coordinates respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54c2a0ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f938371980f045b4b47b190bdc1dd973",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter widget with unique id: f938371980f045b4b47b190bdc1dd973"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//PandasScatter(inputFile, x, y, outputFile);\n",
    "PandasScatter(\"housing.csv\", \"longitude\", \"latitude\", \"output.png\");\n",
    "auto im = xw::image_from_file(\"output.png\").finalize();\n",
    "im"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa065eb7",
   "metadata": {},
   "source": [
    "Let's add some colour to the scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3fef937e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dba3ae5c957d4dc7b5025a32e20bed52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter widget with unique id: dba3ae5c957d4dc7b5025a32e20bed52"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//PandasScatterColor(inputFile, x, y, label, c, outputFile);\n",
    "PandasScatterColor(\"housing.csv\",\"longitude\",\"latitude\",\"Population\",\"median_house_value\",\"output1.png\");\n",
    "auto im = xw::image_from_file(\"output1.png\").finalize();\n",
    "im"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99694c2d",
   "metadata": {},
   "source": [
    "Let's take it a step further and plot this on top of California map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d22bf50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10408985977f4b25b0332df8a43f7081",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter widget with unique id: 10408985977f4b25b0332df8a43f7081"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//PandasScatterMap(inputFile, imgFile, x, y, label, c, outputFile);\n",
    "PandasScatterMap(\"housing.csv\",\"california.png\",\"longitude\",\"latitude\",\"Population\",\"median_house_value\",\"output2.png\");\n",
    "auto im = xw::image_from_file(\"output2.png\").finalize();\n",
    "im"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c150477",
   "metadata": {},
   "source": [
    "<h3>Correlation</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7cd3d78d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "853e9346dae6437aa87ca0d5acfe519f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter widget with unique id: 853e9346dae6437aa87ca0d5acfe519f"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heatmap(\"housing.csv\", \"coolwarm\", \"Correlation Heatmap\", true);\n",
    "auto img = xw::image_from_file(\"Correlation Heatmap.png\").finalize();\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d32757f",
   "metadata": {},
   "source": [
    "<h3>Train-Test Split</h3>\n",
    "The dataset needs to be splitted into training and testing set for tarining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "chubby-water",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Labels are median_house_value which is row 8\n",
    "arma::rowvec labels =\n",
    "    arma::conv_to<arma::rowvec>::from(encoded_dataset.row(8));\n",
    "encoded_dataset.shed_row(8);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "vital-lebanon",
   "metadata": {},
   "outputs": [],
   "source": [
    "arma::mat trainSet, testSet;\n",
    "arma::rowvec trainLabels, testLabels;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ruled-refrigerator",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Split dataset randomly into training set and test set.\n",
    "data::Split(encoded_dataset, labels, trainSet, testSet, trainLabels, testLabels,\n",
    "    0.2 /* Percentage of dataset to use for test set. */);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab01601",
   "metadata": {},
   "source": [
    "### Training the linear model\n",
    "\n",
    "Regression analysis is the most widely used method of prediction. Linear regression is used when the dataset has a linear correlation and as the name suggests, multiple linear regression has one independent variable (predictor) and one or more dependent variable(response).\n",
    "\n",
    "The simple linear regression equation is represented as y = $a + b_{1}x_{1} + b_{2}x_{2} + b_{3}x_{3} + ... + b_{n}x_{n}$ where $x_{i}$ is the ith explanatory variable, y is the dependent variable, $b_{i}$ is ith coefficient and a is the intercept.\n",
    "\n",
    "To perform linear regression we'll be using `LinearRegression()` api from mlpack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "chemical-inside",
   "metadata": {},
   "outputs": [],
   "source": [
    "using namespace mlpack::regression;\n",
    "LinearRegression lr(trainSet, trainLabels, 0.5);\n",
    "// The above line creates and train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "sensitive-sociology",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Let's create a output vector for storing the results.\n",
    "arma::rowvec output; \n",
    "lr.Predict(testSet, output);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "empty-senator",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.ComputeError(trainSet, trainLabels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "circular-donna",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.74874e+09"
     ]
    }
   ],
   "source": [
    "std::cout<<lr.ComputeError(trainSet, trainLabels);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba89a8f",
   "metadata": {},
   "source": [
    "Let's manually check some predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "laden-drawing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174300\n",
      "190507\n"
     ]
    }
   ],
   "source": [
    "std::cout << testLabels[1] << std::endl;\n",
    "std::cout << output[1] << std::endl;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "01849ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170500\n",
      "203024\n"
     ]
    }
   ],
   "source": [
    "std::cout << testLabels[7] << std::endl;\n",
    "std::cout << output[7] << std::endl;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f99b7099",
   "metadata": {},
   "outputs": [],
   "source": [
    "arma::mat preds;\n",
    "preds.insert_rows(0, testLabels);\n",
    "preds.insert_rows(1, output);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0adaac15",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlpack::data::Save(\"preds.csv\", preds);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600f2f3f",
   "metadata": {},
   "source": [
    "### Model Evaluation\n",
    "Test data is visualized with `testLables` and `output`, the blue points indicates the data points and the blue line indicates the regression line or best fit line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "810f1836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e350347bea84528bfc8ad34775eff1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter widget with unique id: 2e350347bea84528bfc8ad34775eff1b"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lmplot(\"predictions.csv\", \"predsScatter\");\n",
    "auto img = xw::image_from_file(\"predsScatter.png\").finalize();    \n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "11a44e68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "739a2b0617ff402ab08664e833fb9339",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter widget with unique id: 739a2b0617ff402ab08664e833fb9339"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "histplot(\"predictions.csv\", \"Distribution of residuals\");\n",
    "auto img = xw::image_from_file(\"Distribution of residuals.png\").finalize();    \n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4f1df6",
   "metadata": {},
   "source": [
    "## Evaluation Metrics for Regression model\n",
    "\n",
    "In the Previous cell we have visualized our model performance by plotting the best fit line. Now we will use various evaluation metrics to understand how well our model has performed.\n",
    "\n",
    "* Mean Absolute Error (MAE) is the sum of absolute differences between actual and predicted values, without considering the direction.\n",
    "$$ MAE = \\frac{\\sum_{i=1}^n\\lvert y_{i} - \\hat{y_{i}}\\rvert} {n} $$\n",
    "* Mean Squared Error (MSE) is calculated as the mean or average of the squared differences between predicted and expected target values in a dataset, a lower value is better\n",
    "$$ MSE = \\frac {1}{n} \\sum_{i=1}^n (y_{i} - \\hat{y_{i}})^2 $$\n",
    "* Root Mean Squared Error (RMSE), Square root of MSE yields root mean square error (RMSE) it indicates the spread of the residual errors. It is always positive, and a lower value indicates better performance.\n",
    "$$ RMSE = \\sqrt{\\frac {1}{n} \\sum_{i=1}^n (y_{i} - \\hat{y_{i}})^2} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "240d935d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 49434.7\n",
      "Mean Squared Error: 4.78e+09\n",
      "Root Mean Squared Error: 69137.5\n"
     ]
    }
   ],
   "source": [
    "// Model evaluation metrics.\n",
    "\n",
    "std::cout << \"Mean Absolute Error: \" << arma::mean(arma::abs(output - testLabels)) << std::endl;\n",
    "std::cout << \"Mean Squared Error: \" << arma::mean(arma::pow(output - testLabels,2)) << std::endl;\n",
    "std::cout << \"Root Mean Squared Error: \" << sqrt(arma::mean(arma::pow(output - testLabels,2))) << std::endl;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f0a28e",
   "metadata": {},
   "source": [
    "We can clearly see that the MAE is 49674, when compared with the median house value doesn't seems to be a good fit. \n",
    "\n",
    "Thus we can conclude that, the simple Linear Regression models is not being able to catch all the features.\n",
    "So, maybe its time for you to try other algorithms. \n",
    "<h5>NOTE : </h5> In the entire ML workflow, you never know exactly which model will perfrom the best. So, usually you try a lot of different algorithms to see which fits the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "C++14",
   "language": "C++14",
   "name": "xcpp14"
  },
  "language_info": {
   "codemirror_mode": "text/x-c++src",
   "file_extension": ".cpp",
   "mimetype": "text/x-c++src",
   "name": "c++",
   "version": "14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
