{"cells":[{"metadata":{},"cell_type":"markdown","source":"[![Binder](https://mybinder.org/badge_logo.svg)](https://lab.mlpack.org/v2/gh/mlpack/examples/master?urlpath=lab%2Ftree%2Fstudent_admission_regression_with_logistic_regression%2Fstudent-admission-logistic-regression-cpp.ipynb)"},{"metadata":{"trusted":false},"cell_type":"code","source":"/**\n * @file student-admission-logistic-regression-cpp.ipynb\n *\n * A simple example usage of Logistic Regression (LR)\n * applied to the Student Admission dataset.\n *\n * We will use a Logistic-Regression model to predict whether a student\n * gets admitted into a university (i.e, the output classes are Yes or No),\n * based on their results on past exams.\n *\n * Data from Andrew Ng's Stanford University Machine Learning Course (Coursera).\n */","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"!wget -q https://lab.mlpack.org/data/student-admission.txt","execution_count":1,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#include <mlpack/xeus-cling.hpp>\n\n#include <mlpack/core.hpp>\n#include <mlpack/methods/logistic_regression/logistic_regression.hpp>","execution_count":2,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"// Header files to create and show the plot.\n#define WITHOUT_NUMPY 1\n#include \"matplotlibcpp.h\"\n#include \"xwidgets/ximage.hpp\"\n\nnamespace plt = matplotlibcpp;","execution_count":3,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"using namespace mlpack;","execution_count":4,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"using namespace mlpack::regression;","execution_count":5,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"// Read the input data.\narma::mat input;\ndata::Load(\"student-admission.txt\", input);","execution_count":6,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"// Print the first 10 rows of the input data.\nstd::cout << input.submat(0, 0, input.n_rows - 1 , 10).t() << std::endl;","execution_count":7,"outputs":[{"name":"stdout","text":"   34.6237   78.0247         0\n   30.2867   43.8950         0\n   35.8474   72.9022         0\n   60.1826   86.3086    1.0000\n   79.0327   75.3444    1.0000\n   45.0833   56.3164         0\n   61.1067   96.5114    1.0000\n   75.0247   46.5540    1.0000\n   76.0988   87.4206    1.0000\n   84.4328   43.5334    1.0000\n   95.8616   38.2253         0\n\n","output_type":"stream"}]},{"metadata":{},"cell_type":"markdown","source":"Historical data from previous students: each student has two exams scores associated and the final admission result (1.0=yes, 0.0=no)."},{"metadata":{"trusted":false},"cell_type":"code","source":"// Plot the input data.\n\n// Get the indices for the labels  0.0 (not admitted).\narma::mat dataset0 = input.cols(arma::find(input.row(2) == 0));\n\n// Get the data to for the indices.\nstd::vector<double> x0 = arma::conv_to<std::vector<double>>::from(dataset0.row(0));\nstd::vector<double> y0 = arma::conv_to<std::vector<double>>::from(dataset0.row(1));\n\n// Get the indices for the label 1.0 (admitted).\narma::mat dataset1 = input.cols(arma::find(input.row(2) == 1.0));\n\n// Get the data to for the indices.\nstd::vector<double> x1 = arma::conv_to<std::vector<double>>::from(dataset1.row(0));\nstd::vector<double> y1 = arma::conv_to<std::vector<double>>::from(dataset1.row(1));\n\nplt::figure_size(800, 800);\n\n// Set the label for the legend.\nstd::map<std::string, std::string> m0;\nm0.insert(std::pair<std::string, std::string>(\"label\", \"not admitted\"));\nplt::scatter(x0, y0, 4, m0);\n\n// Set the label for the legend.\nstd::map<std::string, std::string> m1;\nm1.insert(std::pair<std::string, std::string>(\"label\", \"admitted\"));\nplt::scatter(x1, y1, 4, m1);\n\nplt::xlabel(\"Exam 1 Score\");\nplt::ylabel(\"Exam 2 Score\");\nplt::title(\"Student admission vs. past two exams\");\nplt::legend();\n\nplt::save(\"./plot.png\");\nauto im = xw::image_from_file(\"plot.png\").finalize();\nim","execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"75e1b93113f44ca2ad0a709098eae2c1","version_major":2,"version_minor":0},"text/plain":"A Jupyter widget"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"If the score of the first or the second exam was too low, it might be not enough to be admitted. You need a good balance."},{"metadata":{},"cell_type":"markdown","source":"This is the logistic function to model our admission:\n$P(y=1) = \\frac{1}{1 + e^{-(\\beta_{0} + \\beta_{1} \\cdot x_{1} + ... + \\beta_{n} \\cdot x_{n}) }}$\n\nwhere y is the admission result (0 or 1) and x are the exams scores.\nSince in our example the admission decision is based on two exams (x1 and x2)\n(two exams) we can set n = 2. The next step is to find the correct beta\nparameters for the model by using our historical data as a training set."},{"metadata":{"trusted":false},"cell_type":"code","source":"// Split data into training data X (input) and y (labels) target variable.\n\n// Labels are the last row.\narma::Row<size_t> labels =\n    arma::conv_to<arma::Row<size_t>>::from(input.row(input.n_rows - 1));\ninput.shed_row(input.n_rows - 1);","execution_count":9,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"// Create and train Logistic Regression model.\n//\n// For more information checkout https://mlpack.org/doc/mlpack-git/doxygen/classmlpack_1_1regression_1_1LogisticRegression.html\n// or uncomment the line below.\n// ?LogisticRegression<>\nLogisticRegression<> lr(input, labels, 0.0 /* no regularization */);","execution_count":10,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"// Final beta parameters.\nlr.Parameters().print()","execution_count":11,"outputs":[{"name":"stdout","text":"  -25.1613    0.2062    0.2015\n","output_type":"stream"}]},{"metadata":{"trusted":false},"cell_type":"code","source":"// We can use these beta parameters to plot the decision boundary on the training data.\n// We only need two points to plot a line, so we choose two endpoints:\n// the min and the max among the X training data.\nstd::vector<double> xPlot;\nxPlot.push_back(arma::min(input.row(0)) - 2);\nxPlot.push_back(arma::max(input.row(0)) + 2);\n\nstd::vector<double> yPlot;\nyPlot.push_back((-1.0 / lr.Parameters()(2)) * (lr.Parameters()(1) * xPlot[0] + lr.Parameters()(0)));\nyPlot.push_back((-1.0 / lr.Parameters()(2)) * (lr.Parameters()(1) * xPlot[1] + lr.Parameters()(0)));","execution_count":12,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"// Plot the decision boundary.\n\n// Get the indices for the labels  0.0 (not admitted).\narma::mat dataset0 = input.cols(arma::find(labels == 0));\n\n// Get the data to for the indices.\nstd::vector<double> x0 = arma::conv_to<std::vector<double>>::from(dataset0.row(0));\nstd::vector<double> y0 = arma::conv_to<std::vector<double>>::from(dataset0.row(1));\n\n// Get the indices for the label 1.0 (admitted).\narma::mat dataset1 = input.cols(arma::find(labels == 1.0));\n\n// Get the data to for the indices.\nstd::vector<double> x1 = arma::conv_to<std::vector<double>>::from(dataset1.row(0));\nstd::vector<double> y1 = arma::conv_to<std::vector<double>>::from(dataset1.row(1));\n\nplt::figure_size(800, 800);\nplt::scatter(x0, y0, 4);\nplt::scatter(x1, y1, 4);\n\nplt::plot(xPlot, yPlot);\n\nplt::xlabel(\"Exam 1 Score\");\nplt::ylabel(\"Exam 2 Score\");\nplt::title(\"Student admission vs. past two exams\");\n\nplt::save(\"./decision boundary-plot.png\");\nauto im = xw::image_from_file(\"decision boundary-plot.png\").finalize();\nim","execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"06d78d253ec546e780ea8b5d129f0e1f","version_major":2,"version_minor":0},"text/plain":"A Jupyter widget"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"The blue line is our decision boundary. When your exams score lie below the line then\nprobably (that is the prediction) you will not be admitted to University.\nIf they lie above, probably you will. As you can see, the boundary is not predicting\nperfectly on the training historical data."},{"metadata":{"trusted":false},"cell_type":"code","source":"// Let's say that my scores are 40 in the first exam and 78 in the second one.\narma::mat scores(\"40.0; 78.0\");\n\narma::mat probabilities;\nlr.Classify(scores, probabilities);","execution_count":14,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"probabilities.print()","execution_count":15,"outputs":[{"name":"stdout","text":"   0.7680\n   0.2320\n","output_type":"stream"}]},{"metadata":{},"cell_type":"markdown","source":"Looks like my probability to be admitted at University is only 23%."}],"metadata":{"language_info":{"codemirror_mode":"text/x-c++src","file_extension":".cpp","mimetype":"text/x-c++src","name":"c++","version":"14"},"kernelspec":{"name":"xcpp14","display_name":"C++14","language":"C++14"}},"nbformat":4,"nbformat_minor":4}